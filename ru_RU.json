{
    "很遗憾您这没有能用的显卡来支持您训练": "К сожалению, нет совместимой видеокарты для поддержки вашего обучения.",
    "是": "Да",
    "step1:正在处理数据": "Шаг 1: Обработка данных",
    "step2a:无需提取音高": "Шаг 2a: Пропуск извлечения высоты тона",
    "step2b:正在提取特征": "Шаг 2b: Извлечение характеристик",
    "step3a:正在训练模型": "Шаг 3a: Начало обучения модели",
    "训练结束, 您可查看控制台训练日志或实验文件夹下的train.log": "Обучение завершено. Вы можете проверить журналы обучения в консоли или файл 'train.log' в папке эксперимента.",
    "全流程结束！": "Весь процесс завершен!",
    "本软件以MIT协议开源, 作者不对软件具备任何控制力, 使用软件者、传播软件导出的声音者自负全责. <br>如不认可该条款, 则不能使用或引用软件包内任何代码和文件. 详见根目录<b>使用需遵守的协议-LICENSE.txt</b>.": "Это программное обеспечение с открытым исходным кодом на основе лицензии MIT. Автор не имеет никакого контроля над программным обеспечением. Пользователи, использующие программное обеспечение и распространяющие звуки, экспортированные программным обеспечением, несут полную ответственность. <br>Если вы не согласны с этим условием, вы не можете использовать или ссылаться на какие-либо коды и файлы внутри пакета программного обеспечения. См. корневой каталог <b>Agreement-LICENSE.txt</b> для получения дополнительной информации.",
    "模型推理": "Генерация песен",
    "推理音色": "Голос для генерации:",
    "刷新音色列表和索引路径": "Обновить список голосов и путь к индексу",
    "卸载音色省显存": "Выгрузить голос для экономии памяти GPU:",
    "请选择说话人id": "Выберите идентификатор говорящего/певца:",
    "男转女推荐+12key, 女转男推荐-12key, 如果音域爆炸导致音色失真也可以自己调整到合适音域. ": "Рекомендуется использовать +12 полутонов для преобразования мужского голоса в женский и -12 полутонов для преобразования женского голоса в мужской. Если диапазон звука слишком велик и голос искажается, вы также можете самостоятельно настроить его в подходящем диапазоне.",
    "变调(整数, 半音数量, 升八度12降八度-12)": "Транспонирование (целое число, количество полутонов, повышение на октаву: 12, понижение на октаву: -12):",
    "输入待处理音频文件路径(默认是正确格式示例)": "Введите путь к аудиофайлу для обработки (по умолчанию пример с правильным форматом):",
    "选择音高提取算法,输入歌声可用pm提速,harvest低音好但巨慢无比,crepe效果好但吃GPU": "Выберите алгоритм извлечения высоты тона ('pm': быстрое извлечение, но с низким качеством речи; 'harvest': лучшая басовая составляющая, но очень медленная; 'crepe': лучшее качество, но требует много вычислительных ресурсов GPU):",
    "crepe_hop_length": "Длина шага Mangio-Crepe (применяется только к Mangio-Crepe): Длина шага относится к времени, необходимому для скачка голоса на значительную высоту тона. Меньшие значения длины шага требуют большего времени для вывода результата, но дают более точный результат по высоте тона.",
    "特征检索库文件路径": "Путь к файлу базы данных поиска характеристик",
    ">=3则使用对harvest音高识别的结果使用中值滤波，数值为滤波半径，使用可以削弱哑音": "Если >=3: применить медианный фильтр к результатам извлечения высоты тона с помощью алгоритма 'harvest'. Значение представляет радиус фильтрации и может снизить присутствие задушевных звуков.",
    "特征检索库文件路径,为空则使用下拉的选择结果": "Путь к файлу индекса характеристик. Оставьте пустым, чтобы использовать выбранный результат из выпадающего списка:",
    "自动检测index路径,下拉式选择(dropdown)": "Автоматическое обнаружение пути к индексу и выбор из выпадающего списка:",
    "特征文件路径": "Путь к файлу характеристик:",
    "检索特征占比": "Доля характеристик поиска:",
    "后处理重采样至最终采样率，0为不进行重采样": "Передискретизация выходного аудио в постобработке до конечной частоты дискретизации. Значение 0 означает отсутствие передискретизации:",
    "输入源音量包络替换输出音量包络融合比例，越靠近1越使用输出包络": "Используйте огибающую громкости исходного аудио для замены или смешивания с огибающей громкости выходного аудио. Чем ближе соотношение к 1, тем больше используется огибающая громкости выходного аудио:",
    "保护清辅音和呼吸声，防止电音撕裂等artifact，拉满0.5不开启，调低加大保护力度但可能降低索引效果": "Защита безголосых согласных и звуков дыхания для предотвращения артефактов, таких как рывки в электронной музыке. Значение 0.5 отключает защиту. Уменьшение значения усиливает защиту, но может снизить точность индексации:",
    "F0曲线文件, 可选, 一行一个音高, 代替默认F0及升降调": "Файл кривой F0 (необязательно). Один звук на строку. Заменяет значения F0 по умолчанию и изменение высоты тона:",
    "转换": "Конвертировать",
    "输出信息": "Выходная информация",
    "输出音频(右下角三个点,点了可以下载)": "Экспорт аудио (нажмите на три точки в правом нижнем углу, чтобы скачать)",
    "批量转换, 输入待转换音频文件夹, 或上传多个音频文件, 在指定文件夹(默认opt)下输出转换的音频. ": "Массовая конвертация. Введите папку с аудиофайлами для конвертации или загрузите несколько аудиофайлов. Конвертированный аудиофайл будет сохранен в указанной папке (по умолчанию: 'opt').",
    "指定输出文件夹": "Указать папку для сохранения:",
    "输入待处理音频文件夹路径(去文件管理器地址栏拷就行了)": "Введите путь к папке с аудиофайлами для обработки (скопируйте его из адресной строки файлового менеджера):",
    "也可批量输入音频文件, 二选一, 优先读文件夹": "Вы также можете массово вводить аудиофайлы. Выберите один из двух вариантов. Приоритет отдается чтению из папки.",
    "导出文件格式": "Формат экспортируемого файла",
    "伴奏人声分离&去混响&去回声": "Разделение вокала/сопровождения и удаление реверберации",
    "输入待处理音频文件夹路径": "Введите путь к папке с аудиофайлами для обработки:",
    "模型": "Модель",
    "指定输出主人声文件夹": "Укажите папку для сохранения вокала:",
    "指定输出非主人声文件夹": "Укажите папку для сохранения сопровождения:",
    "训练": "Обучение",
    "step1: 填写实验配置. 实验数据放在logs下, 每个实验一个文件夹, 需手工输入实验名路径, 内含实验配置, 日志, 训练得到的模型文件. ": "Шаг 1: Заполните настройки эксперимента. Данные эксперимента хранятся в папке 'logs', каждый эксперимент имеет отдельную папку. Введите вручную путь к имени эксперимента, который содержит конфигурацию эксперимента, журналы и обученные файлы модели.",
    "输入实验名": "Введите имя эксперимента:",
    "目标采样率": "Целевая частота дискретизации:",
    "模型是否带音高指导(唱歌一定要, 语音可以不要)": "Наличие указания по высоте тона в модели (необходимо для пения, необязательно для речи):",
    "版本": "Версия",
    "提取音高和处理数据使用的CPU进程数": "Количество процессорных процессов, используемых для извлечения высоты тона и обработки данных:",
    "step2a: 自动遍历训练文件夹下所有可解码成音频的文件并进行切片归一化, 在实验目录下生成2个wav文件夹; 暂时只支持单人训练. ": "Шаг 2a: Автоматический обход всех файлов в папке обучения, которые можно декодировать в аудио, и выполнение нормализации срезов. Создает 2 папки с WAV-файлами в папке эксперимента. В настоящее время поддерживается только обучение с одним говорящим/певцом.",
    "输入训练文件夹路径": "Введите путь к папке обучения...",
    "请指定说话人id": "Пожалуйста, укажите идентификатор говорящего/певца:",
    "处理数据": "Обработка данных",
    "step2b: 使用CPU提取音高(如果模型带音高), 使用GPU提取特征(选择卡号)": "Шаг 2b: Использовать CPU для извлечения высоты тона (если модель имеет высоту тона), использовать GPU для извлечения признаков (выберите индекс GPU):",
    "以-分隔输入使用的卡号, 例如   0-1-2   使用卡0和卡1和卡2": "Введите индексы GPU, разделенные '-', например, 0-1-2, чтобы использовать GPU 0, 1 и 2:",
    "显卡信息": "Информация о GPU",
    "选择音高提取算法:输入歌声可用pm提速,高质量语音但CPU差可用dio提速,harvest质量更好但慢": "Выберите алгоритм извлечения высоты тона ('pm': быстрое извлечение, но низкое качество речи; 'dio': улучшенная речь, но медленное извлечение; 'harvest': лучшее качество, но медленное извлечение):",
    "特征提取": "Извлечение признаков",
    "step3: 填写训练设置, 开始训练模型和索引": "Шаг 3: Заполните настройки обучения, начните обучение модели и индекса",
    "保存频率save_every_epoch": "Частота сохранения (save_every_epoch):",
    "总训练轮数total_epoch": "Общее количество эпох обучения (total_epoch):",
    "每张显卡的batch_size": "Размер пакета на каждом GPU:",
    "是否仅保存最新的ckpt文件以节省硬盘空间": "Сохранять только самый последний файл '.ckpt', чтобы сэкономить место на диске:",
    "否": "Нет",
    "是否缓存所有训练集至显存. 10min以下小数据可缓存以加速训练, 大数据缓存会炸显存也加不了多少速": "Кэшировать все обучающие наборы в память GPU. Кэширование небольших наборов данных (длительностью менее 10 минут) может ускорить обучение, но кэширование больших наборов данных потребует много памяти GPU и может не привести к значительному увеличению скорости:",
    "是否在每次保存时间点将最终小模型保存至weights文件夹": "Сохранять конечную небольшую модель в папку 'weights' при каждом сохранении:",
    "加载预训练底模G路径": "Загрузить предварительно обученную базовую модель G по пути:",
    "加载预训练底模D路径": "Загрузить предварительно обученную базовую модель D по пути:",
    "训练模型": "Обучение модели",
    "训练特征索引": "Обучение индекса признаков",
    "一键训练": "Однокнопочное обучение",
    "ckpt处理": "Обработка ckpt",
    "模型融合, 可用于测试音色融合": "Слияние моделей, можно использовать для тестирования слияния тембра",
    "A模型路径": "Путь к модели A:",
    "B模型路径": "Путь к модели B:",
    "A模型权重": "Вес (w) модели A:",
    "模型是否带音高指导": "Наличие модели с управлением высотой тона:",
    "要置入的模型信息": "Информация о модели для вставки:",
    "保存的模型名不带后缀": "Имя сохраняемой модели (без расширения):",
    "模型版本型号": "Версия архитектуры модели:",
    "融合": "Слияние",
    "修改模型信息(仅支持weights文件夹下提取的小模型文件)": "Изменение информации о модели (поддерживается только для малых файлов моделей, извлеченных из папки 'weights')",
    "模型路径": "Путь к модели:",
    "要改的模型信息": "Информация о модели, которую нужно изменить:",
    "保存的文件名, 默认空为和源文件同名": "Имя файла для сохранения (по умолчанию: такое же, как у исходного файла):",
    "修改": "Изменить",
    "查看模型信息(仅支持weights文件夹下提取的小模型文件)": "Просмотр информации о модели (поддерживается только для малых файлов моделей, извлеченных из папки 'weights')",
    "查看": "Просмотр",
    "模型提取(输入logs文件夹下大文件模型路径),适用于训一半不想训了模型没有自动提取保存小文件模型,或者想测试中间模型的情况": "Извлечение модели (введите путь к большому файлу модели в папке 'logs'). Это полезно, если вы хотите остановить обучение на полпути и вручную извлечь и сохранить небольшой файл модели, или если вы хотите протестировать промежуточную модель:",
    "保存名": "Имя сохранения:",
    "模型是否带音高指导,1是0否": "Наличие у модели управления высотой тона (1: да, 0: нет):",
    "提取": "Извлечь",
    "Onnx导出": "Экспорт Onnx",
    "RVC模型路径": "Путь к модели RVC:",
    "Onnx输出路径": "Путь экспорта Onnx:",
    "MoeVS模型": "Модель MoeVS",
    "导出Onnx模型": "Экспортировать модель Onnx",
    "常见问题解答": "Часто задаваемые вопросы (FAQ)",
    "招募音高曲线前端编辑器": "Набор редакторов переднего плана для кривых высоты тона",
    "加开发群联系我xxxxx": "Присоединяйтесь к группе разработчиков и свяжитесь со мной по xxxxx",
    "点击查看交流、问题反馈群号": "Щелкните, чтобы просмотреть номер группы для общения и обратной связи по вопросам",
    "xxxxx": "xxxxx",
    "加载模型": "Загрузить модель",
    "Hubert模型": "Модель Hubert",
    "选择.pth文件": "Выберите файл .pth",
    "选择.index文件": "Выберите файл .index",
    "选择.npy文件": "Выберите файл .npy",
    "输入设备": "Устройство ввода",
    "输出设备": "Устройство вывода",
    "音频设备(请使用同种类驱动)": "Аудиоустройство (пожалуйста, используйте драйвер того же типа)",
    "响应阈值": "Порог отклика",
    "音调设置": "Настройки тона",
    "Index Rate": "Скорость индексации",
    "常规设置": "Общие настройки",
    "采样长度": "Длина сэмпла",
    "淡入淡出长度": "Длительность плавного появления и исчезновения",
    "额外推理时长": "Дополнительное время вывода",
    "输入降噪": "Шумоподавление на входе",
    "输出降噪": "Шумоподавление на выходе",
    "性能设置": "Настройки производительности",
    "开始音频转换": "Начать преобразование аудио",
    "停止音频转换": "Остановить преобразование аудио",
    "推理时间(ms):": "Время вывода (мс):",
    "人声伴奏分离批量处理， 使用UVR5模型。 <br>合格的文件夹路径格式举例： E:\\codes\\py39\\vits_vc_gpu\\白鹭霜华测试样例(去文件管理器地址栏拷就行了)。 <br>模型分为三类： <br>1、保留人声：不带和声的音频选这个，对主人声保留比HP5更好。内置HP2和HP3两个模型，HP3可能轻微漏伴奏但对主人声保留比HP2稍微好一丁点； <br>2、仅保留主人声：带和声的音频选这个，对主人声可能有削弱。内置HP5一个模型； <br> 3、去混响、去延迟模型（by FoxJoy）：<br>  (1)MDX-Net(onnx_dereverb):对于双通道混响是最好的选择，不能去除单通道混响；<br>&emsp;(234)DeEcho:去除延迟效果。Aggressive比Normal去除得更彻底，DeReverb额外去除混响，可去除单声道混响，但是对高频重的板式混响去不干净。<br>去混响/去延迟，附：<br>1、DeEcho-DeReverb模型的耗时是另外2个DeEcho模型的接近2倍；<br>2、MDX-Net-Dereverb模型挺慢的；<br>3、个人推荐的最干净的配置是先MDX-Net再DeEcho-Aggressive。": "Пакетная обработка для разделения вокала и аккомпанемента с использованием модели UVR5.<br>Пример правильного формата пути к папке: D:\\путь\\к\\входной\\папке (скопируйте его из строки адреса файлового менеджера).<br>Модель разделена на три категории:<br>1. Сохранить вокал: выберите эту опцию для аудио без гармоний. Она сохраняет вокал лучше, чем HP5. Включает две встроенные модели: HP2 и HP3. HP3 может немного пропускать аккомпанемент, но сохраняет вокал немного лучше, чем HP2.<br>2. Сохранить только основной вокал: выберите эту опцию для аудио с гармониями. Она может ослабить основной вокал. Включает одну встроенную модель: HP5.<br>3. Модели удаления реверберации и задержки (от FoxJoy):<br>  (1) MDX-Net: лучший выбор для удаления стерео-реверберации, но не может удалить моно-реверберацию;<br> (234) DeEcho: удаляет эффекты задержки. Агрессивный режим удаляет более полностью, чем нормальный режим. DeReverb дополнительно удаляет реверберацию и может удалить моно-реверберацию, но не очень эффективно для сильно реверберирующего высокочастотного содержимого.<br>Примечания по удалению реверберации/задержки:<br>1. Время обработки модели DeEcho-DeReverb примерно в два раза дольше, чем у двух других моделей DeEcho.<br>2. Модель MDX-Net-Dereverb работает довольно медленно.<br>3. Рекомендуется наилучшая конфигурация: сначала примените MDX-Net, а затем DeEcho-Aggressive."
}
